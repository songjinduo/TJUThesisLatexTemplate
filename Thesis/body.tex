% !Mode:: "TeX:UTF-8"
% !TEX root = tjumain.tex

\iffalse
\bibliography{reference/reference.bib} % 欺骗latextools获取bib文件
\fi

%%%%%%% 正文 %%%%%%%

\chapter{绪论}

\section{研究背景及意义}

伴随着互联网多媒体技术飞速发展以及智能手机等终端设备的普及，同时因为各种短视频和社交软件的流行，全世界时时刻刻都会产生海量的图像等网络信息。在如今生活中，人们热衷于在微博、微信、Facebook、抖音等社交和短视频软件上通过图片、视频分享生活，图像作为传输信息的载体，包含了丰富的内容，如何从海量图像信息中获取有的人们所需要的信息变得越发困难，因此在计算机视觉领域中如何自动的对图像进行识别有着重要意义。于此同时，在我们现实中的图像信息内容更加复杂，很多时候都存在着大小、比例、遮挡等问题，这使得图像分类方式的研究更具有挑战性和现实意义。同样使得分类逐渐成为人工智能领域一个重要研究方向，并成为了机器学习和模式识别的基本问题。

现阶段机器学习算法大多是通过对已有的大量的数据的学习从而认识某种规律，且运用所认识的规律对未知数据进行预测，最终使计算机获得不断“学习”的能力。依据不同的学习方式可将机器学习分为监督学习、无监督学习、半监督学习以及增强学习。监督学习是利用已知类别的数据样本学习并且调整分类器模型参数，使其不管输入什么待测样本，其输出结果都能达到预期结果。监督学习的训练集要求包括输入和输出，即特征和目标。训练集中的目标一般是由人手工标注的。监督学习包括回归分析和统计分类两大基本任务。

分类任务指的是当且仅当预测样本的输出取值范围是有限个离散值，也就是说预测未知样本所属的类别属性。图像分类依据图像中目标所反映的不同特征，把这些目标区分开的方式。图像分类技术在现在的生活中有着普遍应用，例如支付宝以及各种支付软件人脸支付系统，智能手机解锁人脸识别系统，医疗领域中病变区域的识别，以及军事中地理信息的分辨等都是以图像分类技术为基础。

传统分类问题以怎样将待预测目标精准地划分到某一类中为探究目标.假如待预测的目标类别中仅仅包含一个或两个候选类, 那么这类问题被称作单分类或二值分类问题，也就是说预测该未知样本是否属于该类别。假如候选类别的数目有很多个，则需要在目标类别中选出一个候选类当作待预测样本的分类结果，那么这类问题就被称为多分类问题。传统分类问题注重的是将图像分类到某个单一的标签，也就是说仅对应唯一的语义信息，所以可以统称它们为单标签分类问题。与单标签分类相比较，因为客观物体本身的复杂性以及多义性，在实际应用中，一个对象同时属于多个类别是普遍存在的，就好比一本书既可以称做“作品”，又可以称它为“纸质出版物”，还可以依据其内容把它分为“经济”、“体育”等读物；可能会有与“金融”、“互联网”、“经济政策”同时有关的一段文本。所以为了能更好的表现出真实目标对象所具有的多语义性，常常用一个合适的标记子集来描述这个对象，多标记分类问题就这样形成了。每个样本都与一个由多个标记构成的相关标记子集合相对应，学习就是以未知样本预测其相应的标记子集为目标。

很显然，多标记分类问题更加符合真实世界客观对象的特性以及规律，但是解决多标记分类问题要面临许多的困难以及挑战。过于庞大的预测输出空间是最主要的困难。因为在多标记分类问题中，预测未知样本所对应的标记子集是我们需要做的，可是伴随着可以利用标记的数量增加，预测过程中所对应的候选标记子集的数量呈现指数型的增涨。毫无疑问想要从这指数级数量的候选子集空间中，选出正确的标签子集当作预测结果是一个巨大的挑战。因此有效减小标记输出空间成为解决多标记学习问题的一个重要策略。其中具有代表性的解决方案是基于地标标记选择和全标记恢复，这种方案通过选择关键的、具有代表性的地标标记和充分利用标记之间的相关性来实现对所有标记的恢复。随着现实世界客观对象变得愈发多义性，多标记分类面临更大的预测输出空间，研究如何有效减小标记输出空间和探索基于地标引导从而恢复所有标记就变得十分必要。

多标记分类问题面临的另一个难点在于如何有效地对单个输入和多个目标类进行建模，而传统的多分类问题只需要对单输入和单目标建立准确的对应关系。这种一对多的特性进一步增加了多标记模型预测所有可能标记的难度。因此准确而显式地对输入样本和多个目标类进行建模也成为解决多标记分类问题的一个重要方向。基于地标选择和全标记恢复的策略主要关注一些关键标记的特性和利用标记之间的相关性，进一步地有研究表明每个类标记都应该具有自己的特定特征[1]，这意味着我们可以拓展关键标记的特性到所有类标记特定的特征学习。随着近些年深度学习[2][3] 的快速发展，更多的传统机器学习算法被扩展到深度神经网络框架中并借助其高度抽象的特征表达能力来获得性能的提升。因此基于深度学习框架下去探索全部标记特定的特征学习就变得非常有意义。

\section{国内外研究现状及存在的问题}
经历了数十年的技术沉淀，多标签分类技术得到了广泛的发展，非常多的对标签图像分类技术被研究人员相继提出，现如今在，多标签图像分类方法整体可被看作传统的多标签分类方式即基于词袋模型（BoW）方法和基于深度学习的方法。

\subsection{传统多标记分类的研究现状及存在的问题}
多标记学习是利用己有的训练数据学习一个模型，该模型可以为一个测试实例分配多个标记。多标记学习算法主要分为两类：问题转换和算法适应 [1]。转化基本问题的方法通常是将多标记问题转化成多个单标记问题进行研究。早期代表性的方法有Binary Relevance (BR) [2]、Classifier Chains (CC) [3]、Label Pairwise (LP) [4]等。基于算法自适应的方法是将已有的分类算法应用到多标记领域来求解多标记问题，典型的方法包括ML-KNN [5]，ML-DT [6]，Rank-SVM [7]等。此外，根据是否考虑标记之间的相关性还可以将多标记学习方法分为三种策略 [8]：a) “一阶策略”方法, 这类方法依次考虑每个标记并对其独立地进行处理，在这过程中并不考虑标签间的相关关系。代表算法有Binary Relevance (BR) [1]。

BR算法是将多标记问题当做多个单标记问题，然后分别给每一个标记训练一个分类器。这种方法思想简单，容易实现，但是因为没有考虑到标记之间的相关性，泛化能力不佳。其他“一阶策略”方法还有有：ML-kNN、ML-DT等。b) “二阶策略”方法，这种方法考虑的则是成对标记中两两之间的相关性，比如，样本所对应的相关标记与无关标记之间的排序关系或者每两个标记间的相互依赖影响等。虽然这种方法在一定程度上利用了标记相关性并且得到不错的泛化性能，但是如果实际应用中标记间存在的相关关系超过了这种二阶相关性，则分类性能会受到影响。代表算法有CLR [8]、LP算法等，其中CLR算法为两两标记重新构建数据集，将问题看做关于这个新建数据集的二分类问题，训练二分类模型，之后引入了人工分割点，将相关标记和不相关标记分隔开，再通过投票的方式比较人工分割点的票数和对应标记的票数确定一个实例是否含有该标记。此外，“二阶策略”方法还包括PS [9]、Rank-SVM等。c) “高阶策略”方法，这种方法在建立分类模型时往往要考虑每个标签以及其他所有标签之间存在的高阶相关关系。很显然这种方法较前两类方法来说对于真实世界中的复杂标签相关性拥有更强的建模能力，但是同时也有使得模型过于复杂的可能，从而导致大规模数据问题很难处理。典型算法有RAkEL [11]、ECC [12]、EPS [10]等，其中RAkEL通过从标记空间中随机选择k个标记作为新的标记空间训练一个分类器，该过程重复多次得到多个分类器，在测试阶段将所有分类器的输出结果做集成得到最终的结果。

上述方法主要是考虑如何有效捕获标记之间的相关性，为了进一步减小标记空间，一些学者提出基于地标选择的方法 [13][14]，这种方法首先在标记空间中选择一个小的标记集合作为地标性标记，这些地标性标记在标记空间中通常具有代表性，并且能和其他标记建立内部依赖关系。MOPLMS[13] 应用组稀疏学习策略去选择少量的标记作为地标标记，这些地标标记能重构出其他标记。ML-CSSP [14] 基于随机采样来进行地标选择，这里的每个类标记的采样概率反应了它在所有类标记中的重要性。尽管这些方法在一定程度上减小了标记空间，然而，这些方法将地标选择和地标预测分成了两个独立的步骤，这样即使其他的标记能被地标标记很好地恢复出来，但是地标标记本身可能很难通过输入样本被准确预测出来。

除了考虑标记之间的相关性和减小标记空间，最近，一些工作[15][16] 旨在从特征空间也学习某种关系，然后将这种关系作用到标记空间从而使得标记空间更加丰富。RELIAB[15] 和MLFE[16] 这两种方法将特征空间中实例与实例之间的关系传递到标记空间中，认为在实例空间中相近的实例在标记空间中也是相似的。此外，Jian等人提出的MIFS[20] 方法不仅通过聚类的方式挖掘了标记之间的相关性，同时也利用了特征空间的相关性。


\subsection{深度多标记分类的研究现状及存在的问题}

传统的多标记分类方法通常利用手工提取好的特征，无法端到端地去训练和学习模型，随着深度学习在图像分类领域的快速发展，很多研究工作开始直接利用深度卷积网络对图像进行特征提取，并设计和构建端到端的可训练模型。Gong等人[18] 将深度神经网络和基于排序的学习策略集合起来去解决图像标注问题；Hu等人[19] 提出一种结构化的推理神经网络去迁移多标记预测到多个语义概念层上；Wang等人[20] 将多标记图像分类转换成一个序列预测问题，并且用循环神经网络去探索标记之间的语义依赖。

为了进一步提高对图像的表达能力，最近一些工作[21] [22] 引入了注意力机制。Wang等人[21] 引入了一个空间转换层去定位特征映射中的重要区域；Guo等人[22] 提出了注意力一致性的假设并且设计了一个两分支的网络，用原始图像和转换后的图像作为输入。这些基于注意力机制的方法虽然在多标记分类任务上已经取得了不错的效果，然而，他们没有考虑到类标记和局部视觉区域的准确的对应关系。主要原因是基于注意力机制的方法往往只利用了较弱的监督信息，即：“一袋标记”对“整张图像”而不是“特定的标记”对“特定的图像区域”。

此外，图结构被广泛应用于建模标记依赖和捕获标记之间复杂的相关性。一些基于概率图模型的方法包括条件随机场[23]，依赖网络[24] 和共现矩阵[25]。最近，Li等人[26] 在标记互信息矩阵上引入最大生成树算法去构建标记图；Li等人[27] 使用图Lasso框架学习图像依赖的条件标记结构；Lee等人[28] 通过合并结构化的知识图来提出了一种新的标记信息传播机制；Chen等人[29] 首次提出一个基于图卷积网络的模型去捕获标记之间的相关性，它应用图卷积网络去映射标记表达到内部依赖目标分类器，但是该模型的多标记预测是直接用学到的目标分类器和全局的图像特征之间的相关性得分来表达，没有有效利用图像的局部特征。

\section{研究内容}
本文介绍以及分析了图像分类，尤其是多标签图像分类在机器学习领域的相关技术与研究，重点是深度学习方面。主要从问题转化方法和算法适应两个方面介绍多标签分类算法。本文中对于多标签图像分类问题，我们介绍并实验一种基于图卷积神经网络端到端的模型，它拥有多不例网络以及全局先验网络，不仅可以有效提取以及利用全局图像先验，更能学习良好的局部图像特征，再将二者有机融合。其针对标签之间相关性的建模以及通过相关性提升多标签分类精度有很好的效果。

\section{文章结构}
本文分析和讨论了基于深度学习的图像多标签分类相关理论和关键方法。针对多标签分类方法目前仍旧存在的问题以及模型设计的不完善，基于原有的方法和模型，通过一定的改进和融合，提出两种基于标签关联的多标签图像分类方法，通过试验分析了方法的优势和不足之处并据此明确此以后研究的方向。
 
第1章为绪论。本章非常详细地介绍和分析了多标签图像分类的课题来源、课题的研究意义以及国内外发展现状，并且阐述了图像多标签分类技术在实际生活方面的研究价值，从整体上说明本文的结构。

第2章  在这一章中我们对传统图像分类、基于深度学习的图像分类方法、图像多标签分类基本理论等做了重点介绍。首先针对目前多标签分类技术和其在多标签图像分类中应用的部分常见方法进行了系统介绍，其次我也重点阐述了卷积神经网络和循环升神经网络这两种深度网络，以及深度学习在目前多标签图像分类中的应用。

第 3 章本章主要介绍了基于一种新的基于GCN的多标签图像识别模型ML-GCN,介绍了其设计思想、基本理论、以及组成部分。本章主要通过概述，GCN图卷积神经网络介绍，ML-GCN整体框架以及相关系数矩阵介绍四小节对ML-GCN模型相关理论做了全面的介绍。

第 4 章主要围绕实验展开，首先描述评估指标、数据集和实现细节。然后，我们报告在MS-COCO[20]和VOC 2007[5]了两个多标签图像识别数据集的实验验证结果。最后通过消融实验进行验证和探究。
 
第 5 章为总结与展望。对本总体的研究现状做了总结，并且通过实验对比分析了目前部分方法中的优缺点。并且进一步提出自己的见解。
 
\chapter{理论与技术}
\section{基于问题转化的方式}
在现实生活中，通常人们解决复杂的问题习惯将其分解，由大化小。换句话说，就是运用分治思想，把我们要解决解决的问题分解成许多个子问题，使得问题更加容易解决。从根本上讲，其实我们研究多标签图像分类是单标签图像分类向真实世界的衍生。问题转化的多标签图像分类方法是——将多标签图像分类问题转换成一个或多个的单标签图像分类问题，再运用成熟的单标签图像分类方式解决上述问题。

这种“多”转“单”的方法有很多，例如对每一个实例确定或是随机分配的一个标签，抑或是只保留只有一个标签的训练样本，然后用传统的多分类方法去训练。这种方法实际上会导致训练样本损失，因此并不推荐使用。再者，我们还可以将训练样本按每个标签去构造一个训练集，每个样本属于或者不属于此标签，对每个标签单独训练一个分类器，最后将多个分类器的结果合成。还有将每一个多标签都单独的视为一个新标签，在一个更多的标签集上做多分类。而当多标签的样本比较少时，这种方法就会受限。除此之外，对每个有多个标签的样本，复制样本，每个样本具有不同的标签，加入训练集后再使用覆盖分类法。

\subsection{传统的问题转化方法}
单标签分类技术作为机器学习视觉领域的重点研究方向，已具备数十年的技术沉淀，所以现如今的图像分类技术已经具备了基本成熟的框架，特征提却和分类器的构建无论对于传统的图像分类框架还是基于深度学习的图像分类框架都是核心步骤。传统的方法多数采用了Bag-of-Word(BOW)模型处理图像分类问题，即人工设计特征提取方式，下面本文将介绍基本的早期基于问题转化方法。

二元关系法BR(Binary Relevance) [1]，一种经典的基于问题转化方法的算法, 其原理简单来讲就是运用一个个独立的单分类方式解决每个标签的预测, 同时每个标签需要被训练一个独立的分类器, 并且用全部的训练数据对每个分类器进行训练。

为了形象描述,用G表示全部标签的集合, G={λj|j=1, …, n}, 我们在这里的λj看作G中的标签, 同时将H当作多标签数据的训练集, H={ (Xi, Yi) |i=1, …, m}，其第i个样本的特征向量用Xi来表示，Yi (Yi∈L) 被我们看作第i个样本所属的标签集合，如表1提供了一个多标签数据集的例子。

\begin{figure}[htbp!]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/p1p2figure.eps}
	\caption{多标签数据集例子}\label{fig:simuP1P2Result}
	\vspace{-1em}
\end{figure}

通过BR方法，这里每一个标签λj都将产生其自己单独的数据集,并且每个数据集包含训练集中的全部样本, 从而我们会得到N个数据集Hλj (j=1…n) ,在Hλj中，所有数据集中所包含的样本都会被标注出是否属于λj,。BR算法的核心就是通过这个数据集训练得到一个二分类器λj，并且其输出样本仅为是否属于,λj，进一步我们为每一个标签训练一个这样的二分类器。最后对于一个未知类别样本, 将全部二分类器结果组合在一起即得到了该样本最终的标签分类结果。表2显示的是将BR方法将表1转化的结果。

\begin{figure}[htbp!]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/p1p2figure.eps}
	\caption{BR转换的结果}\label{fig:simuP1P2Result}
	\vspace{-1em}
\end{figure}

通过原理分析我们很容易可以发现这种算法并没有考虑标签之间的相互关系，甚至将其直接忽略，所以其分类效果很难达到人们理想状态，基于此在文献[6]作者运用拷贝 (copy) 和带权重拷贝 (copy-weight) 的方法对BR进行了改进，将多标签数据拆分成多条单标签数据, 并给予相应的权重。如图3所示，表示表1通过改进BR改进算法转得到的结果结果，a)为拷贝 (copy)方法，b)为(copy-weight) 的方法。

\begin{figure}[htbp!]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/p1p2figure.eps}
	\caption{BR改进转换结果}\label{fig:simuP1P2Result}
	\vspace{-1em}
\end{figure}

组合分类器链ECC (Ensembles of Classifier Chains) [12]是另一种对于BR方法的一种改进, 通过上述阐释我们发现基本的BR算直接忽略签之间的相关性，这直接导致一定程度上的信息损失, 所考虑采用CC 分类器链,该方法可以在保持可接受的计算复杂度的同时对标签相关性进行建模。而作为BR的改进算法，ECC其主要思想便是用一条链将BR产生的N个二分类器链接起来，将训练样本经过每个二分类器的输出结果在加入到下一个而分类器的输入样本中进行训练, 换句话说就将其预测结果添至样本中, 继续代入下一个二分类器中训练。下面我们进一步通过举例说明，例如图3中的数据集中，我们以X为输入空间，Y为标签。

\begin{figure}[htbp!]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/p1p2figure.eps}
	\caption{一个多标签数据集}\label{fig:simuP1P2Result}
	\vspace{-1em}
\end{figure}

假设我们CC链含有四个二分类器，那么我们可以用图四形象刻画训练过程，如图四所示，我们用黄色部分表示输入样本空间，用白色部分表示每个二分类器的输出目标变量。

\begin{figure}[htbp!]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/p1p2figure.eps}
	\caption{ECC转换结果}\label{fig:simuP1P2Result}
	\vspace{-1em}
\end{figure}

通过对CC链基本理论分析我可以发现，在CC链中当二分类器排序顺序的不同时，其结果会有较大变化, 基于此ECC通常采用多条随机产生的不同标签序列的CC组合, 从而减轻单个CC由内部二分类器排列顺序问题而带来的不利影响。

标签幂集法LP (Label Powerset)，被广同样也是一种使用广泛的的基于问题转化的方法。在LP算法中，我们考虑将训练数据中的每种标签集合进行二进制编码，然后使其形成新的单标签。因此研究人员将多标签数据以这种方式转化成单标签数据。原理如图5所示。

\begin{figure}[htbp!]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/p1p2figure.eps}
	\caption{LP转换结果}\label{fig:simuP1P2Result}
	\vspace{-1em}
\end{figure}

在LP算法的有一个显著缺点，就是其不能预测新的标签组合，.Read等人针对这一缺点创造性的将概率分布模型应用到LP中,是的其对未分类数据进行预测时, 可以预测出训练集合中未出现的标签组合[8].如图6所示

\begin{figure}[htbp!]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/p1p2figure.eps}
	\caption{LP概率分布方法}\label{fig:simuP1P2Result}
	\vspace{-1em}
\end{figure}

但是LP算法的复杂度较高, 达到(min{2q, m}·t (D) ) 。LP相对于q的计算复杂度取决于基分类器相对于类数的复杂度，等于训练集中不同的标签集的个数，这个数是最小值(m,2q)的上界，尽管如此它通常要小得多，但仍然会造成一个重要的复杂性问题，尤其是对于m和q值很大的情况。大量的类，其中许多与很少的示例相关联，这也使得学习过程非常困难。

\subsection{深度网络问题转换方法}

通常我们将深度学习理解为由许多非线性转换组成的体系结构，从而通过这种方式来抽象的表示输入对象。单标签图像数分类问题中深度卷积神经网络(CNN)取得了不同凡响的效果，因此得到了相关研究人员的普遍认可，从而使其近年来被广泛运用到多标签图像分类领域。

将深度卷积网络方法和SVM这一种传统的二分类器相结合，形成了CNN-SVM 模型。这种方法首先使用Image Net数据集预训练出来的卷积神经网络来提取待分类图像的语义特征，之后使用 SVM 方法对不同特征进行分类。由于SVM 是一种二分类器，无法直接进行多分类，基于此，CNN-SVM模型针对每一个类都分别构建了训练数据集，在针对每个类分别构建数据集的过程中将目标类的图像作为参考正样本，将其他全部的类别图像当作负样本而训练一个 SVM 分类器，在预测阶段中，将卷积网络中输出的所有图像语义特征逐次输入到各个 SVM 分类器中判断，以此得到图像中最终包含哪些具体目标。

除过利用多个SVM 分类器把多标签的图像分类问题转化为多个单标签的图像分类问题之外，通过图像分块且分别识别各图像块中的目标，是针对这种问题的另一种问题转换方式。其基本原理是通过相应算法将输入的图像合理分块，并使用CNN深度卷积神经网络为每一块图像分别预测其概率分布，最终的预测结果是利用融合算法将全部图像块融合得到的，其工作原理如图7所示。

\begin{figure}[htbp!]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/p1p2figure.eps}
	\caption{图分块识别框架模型}\label{fig:simuP1P2Result}
	\vspace{-1em}
\end{figure}

该方法中相应的图片分块算法多种多样，比如使用滑动窗口的方法将所输入的图像依次划分为大小不均一的数个图像块，然后通过计算各个图像块与训练集中图像的标注位置框的交并比，确定该图像块属于无关背景还是前景目标。在本文中使用的融合算法如下：

其中M是该图像分块后图像块的数目，y(Cn|Pi)k是图像块Pi中类Cn在神经网络中对应的输出值， k是大于1的常数。较高的k值会关注得分最高的图像块，相反弱化得分较低或适中的图像块的贡献。目标的大小、遮挡等一系列问题在多标签图像中比较常见，不同数据集图像的特征分布存在着较大差异，所以简单的采用滑动窗口实现分块的方式容易引起较多的无关背景，所以该方法不具备较好的鲁棒性。

\section{基于算法适应的方法}
目前，基于卷积神经网络的单标签图像分类算法已相对较为成熟。基于算法适应的方法的原理是利用特定的方式方法改造单标签的图像分类算法，以使其能够很好地用于解决多标签的图像分类问题中。能够用于改造的算法种类较多，例如通过相应方式改造boost kNN、SVM等算法以进行多分类。基于kNN算法的改造算法在实现多标签分类时能够加入先验概率，且能对输出的标签进行排序。基于SVM的多种改造算法中，有的研究者将L个二分类的算法训练结果加入到训练集中，之后再重复一次分类，不同的标签之间的依赖关系在这个方法中被考虑了进来，此法也是利用多个分类器进行叠加的一种特殊情况。还有的研究者在改造算法中采用了相关规则的挖掘方法。常用的改造方法主要分为两类，基于损失函数的改造方法和基于基础结构的改造方法，基于损失函数的方法通常根据对多标签图像分类的特性和特点设计了专用的损失函数，基于基础结构的方法的原理是在现有网络基础上进行优化改进，使其能够较好适应多标签分类研究任务。

\subsection{基于损失函数改造的方式}
在机器学习中，损失函数是用来衡量预测值与实际值之间差距的指标。与之类似，在图片分类的过程中损失函数也被用来衡量算法的预测结果与真实标签之间的误差，在深度学习模型中它一般起到调控和指挥的重要作用。在训练模型的过程中，运用损失函数计算算法预测误差，之后根据反向传播算法对网络的参数进行实时更新，在优化算法的作用下逐步的迭代，最终促使损失函数达到最优点。现如今在机器学习领域，不断有新的损失函数被提出，通常可针对不同任务的特点设计针对性的损失函数。

交叉熵是分类任务中一种常用的损失函数，它一般被用来评价当前训练所得到的概率分布和实际的真实分布之间的误差情况，通过减小交叉熵就可以提高算法模型的预测准确率。

其中 p(x)是指数据集真实的概率分布，q(x)是算法模型计算出来估计的概率分布。
对于二分类模型的交叉熵损失函数

在这里我们 f(x)可以是sigmoid函数。或深度学习中的其它激活函数。而 y(i)∈0,1。sigmoid交叉熵损失函数通常适合用在多标签的图像分类任务中。

平方损失函数是一种逻辑上比较简单的损失函数。它是指算法的预测值与实际值之差的平方，一般通过计算预测值和标注值在欧式空间上的距离差来衡量两者之间的相似度。

平方差函数在多种任务上有着非常广泛的应用，主要有以下几个原因：1）平方差损失函数表达形式简单，计算容易； 2）欧式距离作为一种衡量相似度的常用标准，简单有效；3）其在不同的表示域进行转换后特征性质不变。
针对不同任务的特征需求，研究人员提出了各种不同的适用于多标签分类任务的损失函数。Weston等人提出了把成对排序思想运用于图像分类问题的设想。他们的主要想法是，网络预测的结果中正标签的概率值排序应该比负标签的排序高。具体而言，即使分类器识别错正标签，也应该至少为正标签的排序尽量靠前，基于此想法，Gong等人提出了加权排序的损失函数。

\subsection{基于改进改进基础网络的方法}

基于基础结构改造的方法主要关注点放在了网络的基本结构的改进上。客观世界中许多不同物体会同时出现，因此多标签的图像识别的关键就在于对不同标签间的相关性进行数学建模，故而基于相关性改造基础网络的方法便被研究者不断提出。CNN-RNN就是这种方法的代表模型，它的主要框架为CNN算法和RNN算法两个部分，CNN主要负责提取待分类图片的语义信息，RNN则主要负责建立Image/label的关系与label dependency的模型。这种方法先采用深度神经网络将深度特征从图像中提取出来，之后各个类别标签间的相关性由递归神经网络(RNN)得以捕获，极具创造性地将多标签的分类问题转化为一个序列预测的问题进行处理。这种做法不但学习了对应图像语义的特征，而且也考虑了不同类别标签之间的相互关系。因为全局图像信息存在限制因素，此前对于图像中的部分小物体的精确预测依旧存在很大难度。针对这种现象，提出了RLSD模型，被用于建模各个区域之间潜在的语义特征依赖关系。这个模型有效地建立了潜在的区域级别的语义依赖关系。该模型很好地结合了基于区域的局部特征与基于建模的标签共现两者的优点，特别是可以针对因为尺寸较小而无法准确预测的图像中存在的小物体，例如“水瓶”，“酒瓶”和”水杯”等。

\section{算法模型}

本章将详细介绍一种新的基于GCN的多标签图像识别模型(ML-GCN)设计思想、基本理论、以及组成部分。本章主要分为四个小节，分别为：概述，GCN图卷积神经网络介绍，ML-GCN整体框架，相关系数矩阵介绍。

\subsection{概述}

在计算机图像处理领域，多标签识别如今已经被当作一项基础任务。与多类别图像分类相比，多标签任务的难度更大，因为其输出空间随类别数呈指数增长。第二章引入问题变换的思想，将多标签问题转化为二值分类问题，提出了一种解决多标签识别问题的简单方法。由于深卷积神经网络在单标签图像分类中的巨大成功，使得二值分类的性能得到了很大的提高。但这些方法忽略了对象间复杂的拓扑结构，因而在本质上存在局限性。正是这个缺陷导致研究人员从多个角度寻找捕捉和探索标签之间相关性的方法。其中包括第二章中介绍的概率图模型或递归神经网络（RNN），它可以显式地对标签依赖性进行建模。与此同时，另一方面，被研究人人员广泛使用的是运用注意力机制来隐式建模对标签之间的相互关系。但是这种方法只考虑了图像目标特征的局部相关性而忽略了图像中标签之间的全局相关性，而全局相关性的需要通过单张图像之外的知识才能推断。
在这一章节中我们主要研究介绍一种基于图卷积网络（GCN）的全新模型，即 ML-GCN（Multi-Label Graph Convolutional Network），用于建立多标签之间的相关性，ML-GCN模型不仅具备较好可扩展性，而且还有较强灵活性。在该方法中，对象分类器不再作为作为一组需要独立学习的参数向量，我们更多的是运用基于GCN的映射函数，从过去的标签中捕获相互依赖的对象分类器。接下来我们把学习得到的的分类器再应用于另一个子网络生成的图像中再现语句，最终可以实现端到端训练。该方法通过嵌入到分类器的映射参数在所有类之间共享的特性对标签相关性进行了隐式建模。与此同时，出于达到明确地建模分类器学习的标签相关性的目的，我们还设计了标签相关矩阵来，通过该矩阵指导GCN中节点间的信息传播。详细的说就是通过重新加权的方案把节点和它的邻域之间的权重做了平衡，从而进行节点特征更新，这使得过度拟合和过度平滑问题得到有效缓解。
对于“如何有效获取目标标签之间的相关性”以及“如何利用这些标签相关性提升分类表现”这两个多标签图像识别的基础问题。该模型主要从一下三个方面设计


\section{行内公式与行间公式}

考虑整个供应链的利润函数$\beta_{SC}$。因为$\frac{\partial\beta_{SC}}{\partial p_1}=q-\int_0^q F(x)\ud x>0$，所以$\beta_{SC}$对$p_1$单调递增，所以：
\begin{equation}
\label{dscNoStgProof0}
\beta_{SC}(q_s,p_{1s},p_{2s})<\beta_{SC}(q_s,p_{1n},p_{2n})
\end{equation}

因为对于$\forall q\in[q_s, q_n)$，有：
\[ \left.\frac{\partial \beta_{SC}}{\partial q}\right|_{(q,p_{1n},p_{2n})}=p_{1n}-c+c_L+(p_{2n}-p_{1n}-c_L)F(q) \]

销售商决策如式~\eqref{rcond}~所示：
\begin{equation}
\label{rcond}
\left\{\begin{array}{l}
p_{1s}=v_h-(v_h-p_2)\mathbb{E}(\varphi) \\
p_{2s}=v_l \\
q_s \in \underset{q \geq 0}{\mathrm{argmax}} \beta_R (q, p_1, p_2) \\
\end{array}\right.
\end{equation}

\section{插图}

当$q=5190$时，$p_{1s}=5.78,p_{2s}=2.95$，图像如图~\ref{fig:simuP1P2Result}~所示。
\begin{figure}[htbp!]
\centering
\includegraphics[width=0.75\textwidth]{figures/p1p2figure.eps}
\caption{最优$p_1, p_2$仿真结果}\label{fig:simuP1P2Result}
\vspace{-1em}
\end{figure}

\section{代码环境}

很多和计算机专业背景相关的同学都会使用到代码环境，使用~\verb|\verb|~指令或者是~\verb|verbatim|~环境固然是一种选择，但是比不上专门的~lstlisting~环境这么专业。

\begin{lstlisting}
int main(int argc, char ** argv) {
    printf("Hello world!\n");
    return 0;
}
\end{lstlisting}

\section{普通表格的绘制方法}

表格应具有三线表格式，其标准格式如表 \ref{tab:table1} 所示。
\begin{table}[htbp]
\caption{符合本科生毕业论文绘图规范的表格}\label{tab:table1}
\vspace{0.5em}\centering\wuhao
\begin{tabular}{ccccc}
\toprule[1.5pt]
$D$(in) & $P_u$(lbs) & $u_u$(in) & $\beta$ & $G_f$(psi.in)\\
\midrule[1pt]
 5 & 269.8 & 0.000674 & 1.79 & 0.04089\\
10 & 421.0 & 0.001035 & 3.59 & 0.04089\\
20 & 640.2 & 0.001565 & 7.18 & 0.04089\\
 5 & 269.8 & 0.000674 & 1.79 & 0.04089\\
10 & 421.0 & 0.001035 & 3.59 & 0.04089\\
20 & 640.2 & 0.001565 & 7.18 & 0.04089\\
 5 & 269.8 & 0.000674 & 1.79 & 0.04089\\
10 & 421.0 & 0.001035 & 3.59 & 0.04089\\
20 & 640.2 & 0.001565 & 7.18 & 0.04089\\
 5 & 269.8 & 0.000674 & 1.79 & 0.04089\\
10 & 421.0 & 0.001035 & 3.59 & 0.04089\\
20 & 640.2 & 0.001565 & 7.18 & 0.04089\\
\bottomrule[1.5pt]
\end{tabular}
\vspace{\baselineskip}
\end{table}

%%%%%%% 结论 %%%%%%%

\addcontentsline{toc}{chapter}{结\quad 论} %添加到目录中

\chapter*{结\quad 论}

得出结论，楼主傻逼。
